{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cf2dbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Run evaluation on the test set after training is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint (optional - if you want to evaluate a saved model)\n",
    "# checkpoint_path = CHECKPOINTS_PATH + \"best_model.pth\"\n",
    "# model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "# print(f\"Loaded checkpoint: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ada10",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = (\n",
    "    CHECKPOINTS_PATH\n",
    "    + f\"eval_results/epoch_{history['best_epoch']}_test_predictions.json\"\n",
    ")\n",
    "with open(predictions_path) as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "print(f\"Generated {len(predictions)} captions\\n\")\n",
    "print(\"Sample predictions:\")\n",
    "for pred in predictions[:10]:\n",
    "    print(f\"  Image {pred['image_id']}: {pred['caption']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494dd2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Test: Evaluation Functions with Mock Data\n",
    "\n",
    "Test the evaluation functions without needing real data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test compute_caption_metrics with mock data\n",
    "print(\"Testing compute_caption_metrics()...\")\n",
    "\n",
    "mock_predictions = {\n",
    "    1: [\"a dog sitting on the grass\"],\n",
    "    2: [\"a cat sleeping on a couch\"],\n",
    "    3: [\"a person riding a bicycle\"],\n",
    "}\n",
    "\n",
    "mock_references = {\n",
    "    1: [\n",
    "        \"a dog is sitting on green grass\",\n",
    "        \"dog on the grass\",\n",
    "        \"a brown dog sits on grass\",\n",
    "    ],\n",
    "    2: [\n",
    "        \"a cat is sleeping on the sofa\",\n",
    "        \"cat napping on couch\",\n",
    "        \"a sleeping cat on a couch\",\n",
    "    ],\n",
    "    3: [\"a man rides a bike\", \"person on a bicycle\", \"someone cycling on the road\"],\n",
    "}\n",
    "\n",
    "metrics = compute_caption_metrics(mock_predictions, mock_references)\n",
    "print(f\"✅ Success! Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluate_captions with mock COCO format\n",
    "print(\"Testing evaluate_captions()...\")\n",
    "\n",
    "mock_coco = {\n",
    "    \"images\": [\n",
    "        {\"id\": 1, \"file_name\": \"img1.jpg\"},\n",
    "        {\"id\": 2, \"file_name\": \"img2.jpg\"},\n",
    "    ],\n",
    "    \"annotations\": [\n",
    "        {\"image_id\": 1, \"id\": 1, \"caption\": \"a dog sitting on grass\"},\n",
    "        {\"image_id\": 1, \"id\": 2, \"caption\": \"dog on the green grass\"},\n",
    "        {\"image_id\": 2, \"id\": 3, \"caption\": \"a cat on a couch\"},\n",
    "        {\"image_id\": 2, \"id\": 4, \"caption\": \"cat sleeping on sofa\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "mock_pred_list = [\n",
    "    {\"image_id\": 1, \"caption\": \"a dog sitting on the grass\"},\n",
    "    {\"image_id\": 2, \"caption\": \"a cat sleeping on the couch\"},\n",
    "]\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "    json.dump(mock_coco, f)\n",
    "    temp_path = f.name\n",
    "\n",
    "try:\n",
    "    metrics = evaluate_captions(mock_pred_list, temp_path)\n",
    "    print(f\"✅ Success! Metrics: {metrics}\")\n",
    "finally:\n",
    "    os.unlink(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04657ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FiftyOne Visualization\n",
    "\n",
    "Interactive visualization of generated captions vs. ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eca4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FiftyOne dataset from evaluation results\n",
    "dataset = create_captioning_dataset(\n",
    "    images_dir=VAL_PATH,\n",
    "    predictions_path=CHECKPOINTS_PATH\n",
    "    + f\"eval_results/epoch_{history['best_epoch']}_test_predictions.json\",\n",
    "    annotations_path=ANNOTATIONS_PATH + \"captions_val2017.json\",\n",
    "    dataset_name=\"caption_eval\",\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse samples in the dataset\n",
    "for sample in dataset.take(5):\n",
    "    print(f\"\\nImage ID: {sample.image_id}\")\n",
    "    print(f\"Generated: {sample.generated_caption}\")\n",
    "    print(f\"References: {sample.reference_captions[:2]}...\")  # Show first 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02984c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch FiftyOne app for interactive exploration\n",
    "# This opens a web browser at http://localhost:5151\n",
    "\n",
    "# Uncomment to launch:\n",
    "# launch_app(dataset)\n",
    "\n",
    "# Or launch without blocking:\n",
    "# session = fo.launch_app(dataset)\n",
    "# session.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e2058",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plot Metrics Over Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation metrics from training history (if available)\n",
    "if history[\"val_metrics\"]:\n",
    "    val_history = history[\"val_metrics\"]\n",
    "    epochs = [m[\"epoch\"] for m in val_history]\n",
    "\n",
    "    # Extract metrics\n",
    "    bleu4 = [m.get(\"BLEU-4\", 0) for m in val_history]\n",
    "    cider = [m.get(\"CIDEr\", 0) for m in val_history]\n",
    "    meteor = [m.get(\"METEOR\", 0) for m in val_history]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(epochs, bleu4, \"b-o\", label=\"BLEU-4\")\n",
    "    ax.plot(epochs, cider, \"r-s\", label=\"CIDEr\")\n",
    "    ax.plot(epochs, meteor, \"g-^\", label=\"METEOR\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Validation Metrics Over Training\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No validation metrics available - train for more epochs to see trends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad4124",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Evaluation Functions:\n",
    "- `compute_caption_metrics(preds, refs)` - Low-level metric computation\n",
    "- `evaluate_captions(predictions, annotations_path)` - Evaluate list of predictions  \n",
    "- `generate_and_evaluate(model, dataset, ...)` - Generate + evaluate in one call\n",
    "- `evaluate_epoch(model, dataset, ...)` - Full epoch eval with file saving\n",
    "\n",
    "### Visualization Functions:\n",
    "- `create_captioning_dataset(...)` - Build FiftyOne dataset\n",
    "- `create_comparison_dataset(...)` - Compare multiple models\n",
    "- `get_low_score_view(...)` / `get_high_score_view(...)` - Filter samples\n",
    "- `launch_app(dataset)` - Interactive web visualization\n",
    "\n",
    "### Metrics:\n",
    "- **BLEU-1/2/3/4**: N-gram precision\n",
    "- **METEOR**: Semantic matching with synonyms\n",
    "- **CIDEr**: Consensus-based TF-IDF weighted (most important for captioning)\n",
    "- **ROUGE-L**: Longest common subsequence\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
