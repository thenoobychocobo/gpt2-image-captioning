{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e6b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7574190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import CocoDataset\n",
    "from src.models import MLPMappingNetwork, TransformerMappingNetwork, ClipCapModel\n",
    "from src.train import train\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token # Because GPT2 does not have a pad token by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041305e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready: 414113 captions for 82783 images.\n"
     ]
    }
   ],
   "source": [
    "# Take note that the embeddings in coco_train2014_image_embeddings.pt are already normalised\n",
    "\n",
    "dataset = CocoDataset(\n",
    "    embeddings_path=\"data/coco_train2014_image_embeddings.pt\",\n",
    "    annotations_path=\"data/coco_train2014_captions.json\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb88962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_ids': tensor([   32,   845,  3424,   290,   880, 24789,  6565, 12436, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " 'clip_embedding': tensor([-2.0582e-02,  5.1814e-02, -1.1414e-02, -2.8239e-03,  1.4750e-02,\n",
       "          2.4026e-02,  3.4900e-02, -2.4130e-02, -2.3070e-02,  5.2361e-04,\n",
       "         -1.5503e-02, -3.9511e-02, -1.9680e-02, -2.1942e-02,  6.5903e-03,\n",
       "         -6.5856e-03, -4.0837e-02,  1.2718e-02,  4.7172e-03,  1.3094e-02,\n",
       "          5.8578e-02, -3.2071e-04,  4.9159e-02,  5.4241e-02, -1.5497e-02,\n",
       "          3.0319e-02, -1.4742e-02, -1.4111e-02,  1.1611e-02, -1.3766e-04,\n",
       "          1.6698e-02,  2.0703e-02, -2.6310e-02, -5.1049e-03, -3.2191e-03,\n",
       "          2.0171e-02, -1.3052e-02, -2.5989e-02,  4.3786e-02,  1.1961e-01,\n",
       "          5.1846e-02, -5.1446e-03, -2.5286e-02, -1.8026e-02,  1.1559e-02,\n",
       "         -2.4161e-01, -2.7725e-04,  2.4275e-02, -3.5560e-02,  3.0177e-02,\n",
       "         -6.1456e-03, -8.1352e-03,  7.6556e-03, -2.4292e-02, -2.6402e-02,\n",
       "          5.0132e-03, -1.2403e-02, -2.2186e-02,  8.8666e-03,  7.8845e-03,\n",
       "         -1.4252e-01,  6.2499e-03, -4.9126e-04,  1.1588e-02, -2.8575e-02,\n",
       "          3.6918e-02,  8.8065e-02,  6.7322e-02,  3.7893e-02,  1.0703e-02,\n",
       "          1.7468e-02, -2.2279e-03,  5.1160e-03, -1.9318e-02, -1.7919e-02,\n",
       "         -2.2108e-02, -5.6126e-03, -3.9967e-03,  1.5198e-02, -3.6106e-03,\n",
       "          2.0927e-02, -1.2315e-02, -8.5748e-03, -5.4652e-03,  1.2335e-02,\n",
       "         -1.9383e-02,  5.6411e-02, -1.9942e-02, -3.9330e-02, -3.2802e-02,\n",
       "         -2.3398e-04,  1.7958e-02, -6.2671e-01, -2.3583e-03,  3.6943e-03,\n",
       "         -6.6642e-03,  2.7383e-02, -2.1180e-02,  3.0012e-02, -1.3414e-02,\n",
       "         -3.7074e-02, -6.3544e-03, -3.6238e-02,  2.1680e-02, -1.3036e-03,\n",
       "         -9.2520e-03, -3.7458e-02, -1.9311e-02,  3.0219e-02, -3.1401e-02,\n",
       "         -2.2399e-02, -5.5564e-02,  2.2100e-02, -1.3514e-02,  1.6889e-02,\n",
       "         -3.5038e-02,  4.3406e-02,  2.3377e-02,  3.4735e-02, -1.0854e-02,\n",
       "          1.2182e-02, -7.3236e-02,  2.6662e-03, -1.6827e-03,  4.2650e-03,\n",
       "          5.7243e-02,  2.4351e-02,  2.4484e-02, -3.0094e-02, -2.3379e-02,\n",
       "          5.8778e-02,  1.1575e-02, -3.4865e-02,  7.4149e-02, -1.6229e-02,\n",
       "         -1.1136e-02,  1.8898e-02,  7.4005e-04, -1.6404e-02,  5.9338e-02,\n",
       "          1.9546e-02,  1.1192e-02,  3.6310e-02,  1.5162e-02, -1.8277e-02,\n",
       "         -2.1558e-02, -3.4326e-03,  6.3984e-02, -3.9570e-03, -1.4554e-02,\n",
       "         -1.7521e-02, -1.9162e-02,  4.0953e-02, -2.2906e-02,  2.8847e-02,\n",
       "         -7.5833e-03, -3.5604e-02, -1.8983e-02,  6.7388e-02, -2.9704e-02,\n",
       "          2.2272e-02, -4.9690e-02, -1.5085e-02, -8.5958e-03,  2.4375e-02,\n",
       "         -1.4034e-02,  9.6996e-03,  1.2705e-02,  5.4347e-02, -5.7951e-02,\n",
       "         -8.0545e-04, -1.2646e-02, -5.5623e-02, -1.2723e-02, -1.1025e-02,\n",
       "          5.6446e-03,  5.4027e-02, -1.0008e-03, -5.0757e-02, -2.4960e-02,\n",
       "          1.7723e-02, -3.6441e-02, -3.6661e-02, -1.7310e-04, -1.1615e-02,\n",
       "          3.7059e-03, -4.9407e-04, -7.1379e-03, -2.8955e-02, -3.5790e-03,\n",
       "          1.9320e-02, -5.8875e-03,  4.2180e-02,  1.1783e-02, -3.9556e-02,\n",
       "         -1.2114e-02,  3.0924e-03, -3.3074e-03, -5.5417e-02, -1.2670e-02,\n",
       "         -1.9290e-02,  4.3675e-03, -1.7470e-02,  2.8992e-02,  1.5066e-02,\n",
       "          1.3392e-02,  2.6474e-03, -8.1170e-03, -9.9125e-03,  4.1116e-02,\n",
       "         -4.0885e-02,  4.5101e-02,  4.9023e-03,  5.3078e-02,  1.9669e-02,\n",
       "         -5.6805e-02,  1.7919e-02, -1.6917e-02,  6.3228e-02,  3.6255e-02,\n",
       "          1.1475e-02,  3.5994e-02,  2.2950e-02, -3.5370e-02, -5.2439e-02,\n",
       "          2.1443e-02,  9.1122e-03,  3.7306e-03, -2.4042e-02, -6.6591e-04,\n",
       "         -1.5903e-04,  4.4488e-03,  2.7428e-03,  6.6216e-02, -3.1478e-02,\n",
       "          3.5560e-02, -1.4346e-02,  5.3852e-03, -1.7006e-02, -2.6247e-02,\n",
       "          1.0817e-03,  1.6810e-02, -3.3376e-02, -1.4084e-02, -3.1389e-02,\n",
       "          3.3838e-02, -8.2535e-03,  2.7891e-02,  2.1485e-02,  6.3412e-03,\n",
       "          4.8261e-02,  4.8587e-02, -1.1980e-02, -1.6729e-03, -5.3115e-02,\n",
       "          3.5437e-02, -5.1926e-03, -1.9397e-03, -4.4041e-02, -4.1354e-03,\n",
       "          7.2557e-03,  1.4379e-02,  3.8309e-02,  8.8323e-04,  5.9146e-02,\n",
       "          3.2826e-03, -2.7162e-02,  1.4954e-02, -1.2486e-02,  4.2267e-02,\n",
       "         -6.8930e-03,  2.3965e-02,  4.3230e-02,  2.4840e-02,  1.6403e-02,\n",
       "         -2.7387e-02,  2.2299e-02, -1.8472e-02,  1.1621e-02, -2.9433e-02,\n",
       "          3.0789e-02, -1.1145e-02,  6.3954e-03,  3.5393e-02,  4.1334e-02,\n",
       "          1.1552e-03, -3.9774e-02,  1.1001e-02, -2.3759e-02, -1.4068e-02,\n",
       "         -3.9434e-02,  3.4524e-03,  3.2674e-02,  3.3433e-03, -1.8258e-02,\n",
       "         -1.6851e-02, -4.2192e-02, -1.9088e-03,  1.0164e-02, -1.4394e-02,\n",
       "         -6.1882e-02,  2.7735e-02, -1.4624e-03,  5.5999e-02,  4.2242e-02,\n",
       "         -1.0791e-02,  3.7435e-03, -1.9481e-02,  3.8478e-02, -3.5680e-02,\n",
       "         -2.9292e-02,  9.3900e-02,  7.3849e-02,  2.8993e-02,  6.6423e-03,\n",
       "          2.3429e-02,  3.8520e-02,  5.4404e-02, -1.0752e-02, -3.4060e-02,\n",
       "          6.1507e-03,  1.9291e-01,  3.1749e-02,  3.8494e-03,  6.4457e-03,\n",
       "         -7.5712e-03,  2.6038e-02, -1.1919e-02, -1.9194e-02, -9.5593e-03,\n",
       "         -1.3861e-02, -1.9535e-02, -1.9049e-02, -2.6075e-03, -1.2003e-02,\n",
       "          1.2552e-02,  1.7314e-02,  2.0962e-02,  6.1092e-03, -1.5275e-02,\n",
       "          2.5368e-03, -6.1853e-02, -2.7191e-02,  7.3802e-03,  3.2945e-02,\n",
       "         -1.3289e-02, -1.7199e-02,  3.2457e-03,  2.5577e-02, -1.6664e-02,\n",
       "          1.2587e-01,  3.4932e-02,  3.8466e-03,  3.6864e-02, -1.8339e-02,\n",
       "          1.9224e-03,  1.5819e-04,  1.5091e-01,  3.1611e-03,  7.3514e-03,\n",
       "         -7.0829e-02,  2.2172e-02,  2.4150e-02,  1.0582e-02, -6.5921e-03,\n",
       "          2.6259e-02, -2.9073e-02, -2.4569e-02,  4.9252e-03,  1.6873e-02,\n",
       "         -3.1452e-03,  9.8312e-03,  4.1336e-02,  1.9215e-02,  3.9632e-02,\n",
       "          3.3852e-02,  1.1335e-01,  7.4295e-03, -3.9533e-02,  1.6404e-02,\n",
       "         -8.6426e-04, -4.8999e-02, -1.5894e-02,  1.2660e-02,  4.2596e-02,\n",
       "         -1.1834e-02,  1.6388e-02,  1.4379e-03, -2.4453e-02,  3.5099e-02,\n",
       "          1.1435e-03,  3.6565e-02,  3.0179e-02,  1.0586e-02, -3.5358e-02,\n",
       "         -3.8325e-02,  1.2903e-02,  8.6186e-03,  5.2778e-02, -1.9727e-02,\n",
       "         -1.6862e-02,  3.5484e-02,  7.1813e-02, -3.3586e-02, -5.5781e-03,\n",
       "          3.5796e-02,  3.8192e-02, -1.5924e-02,  2.9490e-02, -2.0002e-02,\n",
       "          3.0803e-02,  3.6207e-02,  9.9555e-03, -1.4482e-02, -6.3690e-03,\n",
       "          4.1382e-02, -5.0595e-02,  5.1654e-02, -4.2854e-02, -5.0754e-02,\n",
       "         -3.8484e-02, -1.1870e-02,  4.5240e-02, -3.2084e-02, -1.0861e-02,\n",
       "         -1.7430e-03, -1.7761e-02,  3.8419e-02, -1.2895e-01,  1.5810e-02,\n",
       "         -5.9982e-03,  1.7549e-03,  1.0371e-01,  1.2185e-02,  6.9168e-03,\n",
       "         -2.3483e-02, -1.0057e-02, -1.9974e-02,  4.0463e-02, -1.3342e-02,\n",
       "         -2.7936e-03, -2.1189e-02, -6.6260e-03,  2.6048e-02,  2.2862e-03,\n",
       "         -3.1416e-03,  2.3773e-03,  2.1432e-02,  4.6225e-03, -4.3173e-02,\n",
       "          2.1260e-02, -4.0185e-02, -1.9691e-02,  1.8085e-02, -1.7223e-03,\n",
       "         -1.0148e-02, -8.9143e-03,  1.6603e-02,  2.0900e-02,  6.3142e-03,\n",
       "         -1.2782e-02,  6.7136e-03, -5.2315e-03, -5.2316e-03, -1.5185e-03,\n",
       "         -7.2614e-03, -9.3960e-03, -4.1550e-02, -2.0305e-02, -1.6283e-02,\n",
       "         -6.5051e-04,  4.2750e-02,  5.2256e-02, -3.7447e-02, -2.6060e-02,\n",
       "         -1.7270e-02, -3.7010e-02, -3.0201e-03, -1.4892e-02, -1.9468e-02,\n",
       "         -8.2525e-03,  2.7885e-02, -6.5299e-04,  5.1871e-02,  3.9010e-02,\n",
       "          5.2387e-02,  4.8706e-03,  2.7702e-02,  1.7725e-02,  5.5856e-04,\n",
       "          1.6822e-02,  7.0614e-03,  1.4108e-02, -6.7895e-02,  1.7025e-02,\n",
       "          5.4464e-03,  9.5376e-03,  1.2595e-02, -2.9103e-02, -1.7508e-02,\n",
       "          2.5110e-02, -9.9682e-03,  1.8733e-02,  2.6773e-02,  7.4298e-02,\n",
       "          2.8936e-02,  2.4286e-03, -7.2278e-03, -2.5526e-02,  7.1563e-02,\n",
       "         -1.3583e-02, -1.3581e-03]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " 'caption_text': 'A very clean and well decorated empty bathroom',\n",
       " 'image_id': 318556}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c064694",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bb1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': tensor([[   64,  1402,  2933,   318,  4769,   257,  4077,   290,  7872, 16162,\n",
      "         32680, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [43559,  3180,   317, 41153,  3963, 41670, 11651,   367, 15173,  2751,\n",
      "           317, 18671,  3069,  9370, 11651, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   32,  2415,  4769,   257,  7480,   351,   257,  3704,   286, 14256,\n",
      "           319,   340,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   32,  1256,   286,   661,   389,   379,   257,  3148,   810,   867,\n",
      "          9701,   389,  7348,    13, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'clip_embedding': tensor([[-0.0150,  0.0084, -0.0039,  ...,  0.0613,  0.0498,  0.0057],\n",
      "        [-0.0209,  0.0868, -0.0227,  ...,  0.0286,  0.0317,  0.0072],\n",
      "        [ 0.0173,  0.0378, -0.0011,  ...,  0.0375,  0.0240, -0.0318],\n",
      "        [ 0.0002, -0.0025, -0.0486,  ...,  0.0357,  0.0240, -0.0220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'caption_text': ['a small boy is holding a green and yellow toothbrush', 'THIS IS A PHOTO OF SOMEONE HOLDING A CELL PHONE', 'A woman holding a plate with a piece of pizza on it.', 'A lot of people are at a fair where many flags are flying.'], 'image_id': tensor([115275, 116735, 169986, 329799])}\n"
     ]
    }
   ],
   "source": [
    "# View one batch\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    # Dataloader is smart: will stack non-tensor items as well\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87b35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Epoch [1/1], Step [1/103529], Loss: 8.0623\n",
      "Batch 1 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 2 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 3 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 4 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 5 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 6 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 7 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 8 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 9 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 10 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 11 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 12 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 13 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 14 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 15 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 16 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 17 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 18 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 19 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 20 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 21 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 22 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 23 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 24 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 25 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 26 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 27 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 28 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 29 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 30 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 31 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 32 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 33 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 34 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 35 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 36 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 37 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 38 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 39 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 40 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 41 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 42 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 43 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 44 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 45 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 46 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 47 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 48 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 49 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 50 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 51 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 52 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 53 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 54 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 55 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 56 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 57 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 58 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 59 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 60 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 61 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 62 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 63 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 64 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 65 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 66 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 67 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 68 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 69 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 70 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 71 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 72 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 73 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 74 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 75 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 76 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 77 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 78 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 79 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 80 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 81 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 82 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 83 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 84 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 85 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 86 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 87 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 88 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 89 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 90 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 91 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 92 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 93 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 94 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 95 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 96 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 97 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 98 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 99 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 100 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Epoch [1/1], Step [101/103529], Loss: 1.1665\n",
      "Batch 101 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 102 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 103 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 104 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 105 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 106 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 107 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 108 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 109 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 110 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 111 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 112 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 113 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 114 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 115 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 116 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 117 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 118 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 119 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 120 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 121 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 122 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 123 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 124 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 125 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 126 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 127 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 128 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 129 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 130 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 131 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 132 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 133 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 134 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 135 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 136 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 137 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 138 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 139 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 140 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 141 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 142 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 143 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 144 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 145 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 146 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 147 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 148 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 149 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 150 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 151 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 152 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 153 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 154 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 155 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 156 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 157 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 158 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 159 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 160 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 161 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 162 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 163 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 164 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 165 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 166 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 167 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 168 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 169 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 170 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 171 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 172 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 173 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 174 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 175 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 176 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 177 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 178 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 179 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 180 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 181 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 182 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 183 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 184 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 185 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 186 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 187 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 188 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 189 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 190 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 191 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 192 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 193 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 194 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 195 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 196 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 197 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 198 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 199 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 200 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Epoch [1/1], Step [201/103529], Loss: 1.2926\n",
      "Batch 201 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 202 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 203 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 204 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 205 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 206 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 207 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 208 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 209 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 210 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 211 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 212 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 213 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 214 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 215 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 216 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 217 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 218 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 219 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 220 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 221 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 222 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 223 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 224 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 225 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 226 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 227 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 228 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 229 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 230 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 231 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 232 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 233 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 234 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 235 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 236 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 237 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 238 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 239 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 240 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 241 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 242 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 243 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 244 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 245 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 246 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 247 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 248 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 249 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 250 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 251 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 252 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 253 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 254 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 255 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 256 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 257 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 258 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 259 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 260 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 261 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 262 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 263 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 264 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 265 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 266 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 267 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 268 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 269 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 270 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 271 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 272 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 273 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 274 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 275 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 276 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 277 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 278 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 279 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 280 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 281 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 282 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 283 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 284 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 285 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 286 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 287 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 288 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 289 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 290 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 291 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 292 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 293 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 294 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 295 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 296 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 297 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 298 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 299 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 300 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Epoch [1/1], Step [301/103529], Loss: 1.0896\n",
      "Batch 301 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 302 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 303 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 304 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 305 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 306 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m mapping_network \u001b[38;5;241m=\u001b[39m MLPMappingNetwork(\n\u001b[0;32m      2\u001b[0m     prefix_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m ClipCapModel(\n\u001b[0;32m      6\u001b[0m     mapping_network\u001b[38;5;241m=\u001b[39mmapping_network\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hoxia\\Documents\\NLDeeznuts\\gpt2-image-captioning\\src\\train.py:56\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, model, batch_size, num_epochs, device, outputs_dir)\u001b[0m\n\u001b[0;32m     51\u001b[0m attention_mask = batch[\"attention_mask\"].to(device)\n\u001b[0;32m     53\u001b[0m optimizer.zero_grad()\n\u001b[0;32m     55\u001b[0m # Forward pass, model tries to predict the next token given previous tokens and image embeddings\n\u001b[1;32m---> 56\u001b[0m # We do not have to shift the token_ids here because the model's forward method handles that internally\n\u001b[0;32m     57\u001b[0m outputs = model(\n\u001b[0;32m     58\u001b[0m     caption_token_ids=token_ids,\n\u001b[0;32m     59\u001b[0m     clip_image_embeddings=clip_embeddings,\n\u001b[0;32m     60\u001b[0m     attention_mask=attention_mask,\n\u001b[0;32m     61\u001b[0m     labels=token_ids\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m loss = outputs.loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hoxia\\Documents\\NLDeeznuts\\gpt2-image-captioning\\src\\models.py:232\u001b[0m, in \u001b[0;36mClipCapModel.forward\u001b[1;34m(self, caption_token_ids, clip_image_embeddings, attention_mask, labels)\u001b[0m\n\u001b[0;32m    229\u001b[0m caption_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(caption_token_ids)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Obtain the prefix tokens from the CLIP image embeddings via the mapping network\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m prefix_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_image_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Concatenate prefix tokens with the ground-truth caption tokens\u001b[39;00m\n\u001b[0;32m    235\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((prefix_tokens, caption_tokens), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hoxia\\Documents\\NLDeeznuts\\gpt2-image-captioning\\src\\models.py:65\u001b[0m, in \u001b[0;36mMLPMappingNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mReturns a sequence of prefix tokens derived from the input CLIP embedding vectors.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    torch.Tensor: Sequence of prefix tokens of shape (batch_size, prefix_length, gpt_dim)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# x shape: (batch_size, clip_dim)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Project to (batch_size, prefix_length * gpt_dim)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Split the flat output vector into a sequence of prefix_length vectors\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt_dim)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mapping_network = MLPMappingNetwork(\n",
    "    prefix_length=10\n",
    ")\n",
    "\n",
    "model = ClipCapModel(\n",
    "    mapping_network=mapping_network\n",
    ")\n",
    "\n",
    "train(dataset=dataset, model=model, batch_size=batch_size, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c4e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
