{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e6b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7574190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import CocoDataset\n",
    "from src.models import MLPMappingNetwork, TransformerMappingNetwork, ClipCapModel\n",
    "from src.train import train\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601a973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token # Because GPT2 does not have a pad token by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041305e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready: 414113 captions for 82783 images.\n"
     ]
    }
   ],
   "source": [
    "# Take note that the embeddings in coco_train2014_image_embeddings.pt are already normalised\n",
    "\n",
    "dataset = CocoDataset(\n",
    "    embeddings_path=\"data/coco_train2014_image_embeddings.pt\",\n",
    "    annotations_path=\"data/coco_train2014_captions.json\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb88962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_ids': tensor([   32,   845,  3424,   290,   880, 24789,  6565, 12436, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]),\n",
       " 'clip_embedding': tensor([-2.0582e-02,  5.1814e-02, -1.1414e-02, -2.8239e-03,  1.4750e-02,\n",
       "          2.4026e-02,  3.4900e-02, -2.4130e-02, -2.3070e-02,  5.2361e-04,\n",
       "         -1.5503e-02, -3.9511e-02, -1.9680e-02, -2.1942e-02,  6.5903e-03,\n",
       "         -6.5856e-03, -4.0837e-02,  1.2718e-02,  4.7172e-03,  1.3094e-02,\n",
       "          5.8578e-02, -3.2071e-04,  4.9159e-02,  5.4241e-02, -1.5497e-02,\n",
       "          3.0319e-02, -1.4742e-02, -1.4111e-02,  1.1611e-02, -1.3766e-04,\n",
       "          1.6698e-02,  2.0703e-02, -2.6310e-02, -5.1049e-03, -3.2191e-03,\n",
       "          2.0171e-02, -1.3052e-02, -2.5989e-02,  4.3786e-02,  1.1961e-01,\n",
       "          5.1846e-02, -5.1446e-03, -2.5286e-02, -1.8026e-02,  1.1559e-02,\n",
       "         -2.4161e-01, -2.7725e-04,  2.4275e-02, -3.5560e-02,  3.0177e-02,\n",
       "         -6.1456e-03, -8.1352e-03,  7.6556e-03, -2.4292e-02, -2.6402e-02,\n",
       "          5.0132e-03, -1.2403e-02, -2.2186e-02,  8.8666e-03,  7.8845e-03,\n",
       "         -1.4252e-01,  6.2499e-03, -4.9126e-04,  1.1588e-02, -2.8575e-02,\n",
       "          3.6918e-02,  8.8065e-02,  6.7322e-02,  3.7893e-02,  1.0703e-02,\n",
       "          1.7468e-02, -2.2279e-03,  5.1160e-03, -1.9318e-02, -1.7919e-02,\n",
       "         -2.2108e-02, -5.6126e-03, -3.9967e-03,  1.5198e-02, -3.6106e-03,\n",
       "          2.0927e-02, -1.2315e-02, -8.5748e-03, -5.4652e-03,  1.2335e-02,\n",
       "         -1.9383e-02,  5.6411e-02, -1.9942e-02, -3.9330e-02, -3.2802e-02,\n",
       "         -2.3398e-04,  1.7958e-02, -6.2671e-01, -2.3583e-03,  3.6943e-03,\n",
       "         -6.6642e-03,  2.7383e-02, -2.1180e-02,  3.0012e-02, -1.3414e-02,\n",
       "         -3.7074e-02, -6.3544e-03, -3.6238e-02,  2.1680e-02, -1.3036e-03,\n",
       "         -9.2520e-03, -3.7458e-02, -1.9311e-02,  3.0219e-02, -3.1401e-02,\n",
       "         -2.2399e-02, -5.5564e-02,  2.2100e-02, -1.3514e-02,  1.6889e-02,\n",
       "         -3.5038e-02,  4.3406e-02,  2.3377e-02,  3.4735e-02, -1.0854e-02,\n",
       "          1.2182e-02, -7.3236e-02,  2.6662e-03, -1.6827e-03,  4.2650e-03,\n",
       "          5.7243e-02,  2.4351e-02,  2.4484e-02, -3.0094e-02, -2.3379e-02,\n",
       "          5.8778e-02,  1.1575e-02, -3.4865e-02,  7.4149e-02, -1.6229e-02,\n",
       "         -1.1136e-02,  1.8898e-02,  7.4005e-04, -1.6404e-02,  5.9338e-02,\n",
       "          1.9546e-02,  1.1192e-02,  3.6310e-02,  1.5162e-02, -1.8277e-02,\n",
       "         -2.1558e-02, -3.4326e-03,  6.3984e-02, -3.9570e-03, -1.4554e-02,\n",
       "         -1.7521e-02, -1.9162e-02,  4.0953e-02, -2.2906e-02,  2.8847e-02,\n",
       "         -7.5833e-03, -3.5604e-02, -1.8983e-02,  6.7388e-02, -2.9704e-02,\n",
       "          2.2272e-02, -4.9690e-02, -1.5085e-02, -8.5958e-03,  2.4375e-02,\n",
       "         -1.4034e-02,  9.6996e-03,  1.2705e-02,  5.4347e-02, -5.7951e-02,\n",
       "         -8.0545e-04, -1.2646e-02, -5.5623e-02, -1.2723e-02, -1.1025e-02,\n",
       "          5.6446e-03,  5.4027e-02, -1.0008e-03, -5.0757e-02, -2.4960e-02,\n",
       "          1.7723e-02, -3.6441e-02, -3.6661e-02, -1.7310e-04, -1.1615e-02,\n",
       "          3.7059e-03, -4.9407e-04, -7.1379e-03, -2.8955e-02, -3.5790e-03,\n",
       "          1.9320e-02, -5.8875e-03,  4.2180e-02,  1.1783e-02, -3.9556e-02,\n",
       "         -1.2114e-02,  3.0924e-03, -3.3074e-03, -5.5417e-02, -1.2670e-02,\n",
       "         -1.9290e-02,  4.3675e-03, -1.7470e-02,  2.8992e-02,  1.5066e-02,\n",
       "          1.3392e-02,  2.6474e-03, -8.1170e-03, -9.9125e-03,  4.1116e-02,\n",
       "         -4.0885e-02,  4.5101e-02,  4.9023e-03,  5.3078e-02,  1.9669e-02,\n",
       "         -5.6805e-02,  1.7919e-02, -1.6917e-02,  6.3228e-02,  3.6255e-02,\n",
       "          1.1475e-02,  3.5994e-02,  2.2950e-02, -3.5370e-02, -5.2439e-02,\n",
       "          2.1443e-02,  9.1122e-03,  3.7306e-03, -2.4042e-02, -6.6591e-04,\n",
       "         -1.5903e-04,  4.4488e-03,  2.7428e-03,  6.6216e-02, -3.1478e-02,\n",
       "          3.5560e-02, -1.4346e-02,  5.3852e-03, -1.7006e-02, -2.6247e-02,\n",
       "          1.0817e-03,  1.6810e-02, -3.3376e-02, -1.4084e-02, -3.1389e-02,\n",
       "          3.3838e-02, -8.2535e-03,  2.7891e-02,  2.1485e-02,  6.3412e-03,\n",
       "          4.8261e-02,  4.8587e-02, -1.1980e-02, -1.6729e-03, -5.3115e-02,\n",
       "          3.5437e-02, -5.1926e-03, -1.9397e-03, -4.4041e-02, -4.1354e-03,\n",
       "          7.2557e-03,  1.4379e-02,  3.8309e-02,  8.8323e-04,  5.9146e-02,\n",
       "          3.2826e-03, -2.7162e-02,  1.4954e-02, -1.2486e-02,  4.2267e-02,\n",
       "         -6.8930e-03,  2.3965e-02,  4.3230e-02,  2.4840e-02,  1.6403e-02,\n",
       "         -2.7387e-02,  2.2299e-02, -1.8472e-02,  1.1621e-02, -2.9433e-02,\n",
       "          3.0789e-02, -1.1145e-02,  6.3954e-03,  3.5393e-02,  4.1334e-02,\n",
       "          1.1552e-03, -3.9774e-02,  1.1001e-02, -2.3759e-02, -1.4068e-02,\n",
       "         -3.9434e-02,  3.4524e-03,  3.2674e-02,  3.3433e-03, -1.8258e-02,\n",
       "         -1.6851e-02, -4.2192e-02, -1.9088e-03,  1.0164e-02, -1.4394e-02,\n",
       "         -6.1882e-02,  2.7735e-02, -1.4624e-03,  5.5999e-02,  4.2242e-02,\n",
       "         -1.0791e-02,  3.7435e-03, -1.9481e-02,  3.8478e-02, -3.5680e-02,\n",
       "         -2.9292e-02,  9.3900e-02,  7.3849e-02,  2.8993e-02,  6.6423e-03,\n",
       "          2.3429e-02,  3.8520e-02,  5.4404e-02, -1.0752e-02, -3.4060e-02,\n",
       "          6.1507e-03,  1.9291e-01,  3.1749e-02,  3.8494e-03,  6.4457e-03,\n",
       "         -7.5712e-03,  2.6038e-02, -1.1919e-02, -1.9194e-02, -9.5593e-03,\n",
       "         -1.3861e-02, -1.9535e-02, -1.9049e-02, -2.6075e-03, -1.2003e-02,\n",
       "          1.2552e-02,  1.7314e-02,  2.0962e-02,  6.1092e-03, -1.5275e-02,\n",
       "          2.5368e-03, -6.1853e-02, -2.7191e-02,  7.3802e-03,  3.2945e-02,\n",
       "         -1.3289e-02, -1.7199e-02,  3.2457e-03,  2.5577e-02, -1.6664e-02,\n",
       "          1.2587e-01,  3.4932e-02,  3.8466e-03,  3.6864e-02, -1.8339e-02,\n",
       "          1.9224e-03,  1.5819e-04,  1.5091e-01,  3.1611e-03,  7.3514e-03,\n",
       "         -7.0829e-02,  2.2172e-02,  2.4150e-02,  1.0582e-02, -6.5921e-03,\n",
       "          2.6259e-02, -2.9073e-02, -2.4569e-02,  4.9252e-03,  1.6873e-02,\n",
       "         -3.1452e-03,  9.8312e-03,  4.1336e-02,  1.9215e-02,  3.9632e-02,\n",
       "          3.3852e-02,  1.1335e-01,  7.4295e-03, -3.9533e-02,  1.6404e-02,\n",
       "         -8.6426e-04, -4.8999e-02, -1.5894e-02,  1.2660e-02,  4.2596e-02,\n",
       "         -1.1834e-02,  1.6388e-02,  1.4379e-03, -2.4453e-02,  3.5099e-02,\n",
       "          1.1435e-03,  3.6565e-02,  3.0179e-02,  1.0586e-02, -3.5358e-02,\n",
       "         -3.8325e-02,  1.2903e-02,  8.6186e-03,  5.2778e-02, -1.9727e-02,\n",
       "         -1.6862e-02,  3.5484e-02,  7.1813e-02, -3.3586e-02, -5.5781e-03,\n",
       "          3.5796e-02,  3.8192e-02, -1.5924e-02,  2.9490e-02, -2.0002e-02,\n",
       "          3.0803e-02,  3.6207e-02,  9.9555e-03, -1.4482e-02, -6.3690e-03,\n",
       "          4.1382e-02, -5.0595e-02,  5.1654e-02, -4.2854e-02, -5.0754e-02,\n",
       "         -3.8484e-02, -1.1870e-02,  4.5240e-02, -3.2084e-02, -1.0861e-02,\n",
       "         -1.7430e-03, -1.7761e-02,  3.8419e-02, -1.2895e-01,  1.5810e-02,\n",
       "         -5.9982e-03,  1.7549e-03,  1.0371e-01,  1.2185e-02,  6.9168e-03,\n",
       "         -2.3483e-02, -1.0057e-02, -1.9974e-02,  4.0463e-02, -1.3342e-02,\n",
       "         -2.7936e-03, -2.1189e-02, -6.6260e-03,  2.6048e-02,  2.2862e-03,\n",
       "         -3.1416e-03,  2.3773e-03,  2.1432e-02,  4.6225e-03, -4.3173e-02,\n",
       "          2.1260e-02, -4.0185e-02, -1.9691e-02,  1.8085e-02, -1.7223e-03,\n",
       "         -1.0148e-02, -8.9143e-03,  1.6603e-02,  2.0900e-02,  6.3142e-03,\n",
       "         -1.2782e-02,  6.7136e-03, -5.2315e-03, -5.2316e-03, -1.5185e-03,\n",
       "         -7.2614e-03, -9.3960e-03, -4.1550e-02, -2.0305e-02, -1.6283e-02,\n",
       "         -6.5051e-04,  4.2750e-02,  5.2256e-02, -3.7447e-02, -2.6060e-02,\n",
       "         -1.7270e-02, -3.7010e-02, -3.0201e-03, -1.4892e-02, -1.9468e-02,\n",
       "         -8.2525e-03,  2.7885e-02, -6.5299e-04,  5.1871e-02,  3.9010e-02,\n",
       "          5.2387e-02,  4.8706e-03,  2.7702e-02,  1.7725e-02,  5.5856e-04,\n",
       "          1.6822e-02,  7.0614e-03,  1.4108e-02, -6.7895e-02,  1.7025e-02,\n",
       "          5.4464e-03,  9.5376e-03,  1.2595e-02, -2.9103e-02, -1.7508e-02,\n",
       "          2.5110e-02, -9.9682e-03,  1.8733e-02,  2.6773e-02,  7.4298e-02,\n",
       "          2.8936e-02,  2.4286e-03, -7.2278e-03, -2.5526e-02,  7.1563e-02,\n",
       "         -1.3583e-02, -1.3581e-03]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " 'caption_text': 'A very clean and well decorated empty bathroom',\n",
       " 'image_id': 318556}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c064694",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87bb1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_ids': tensor([[   32,  1448,   286,   661, 10311,   319,   262,   736,   286,   281,\n",
      "         20950,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   64,   582, 14284,   510,   257,  1310,   981,  9008,   257, 20790,\n",
      "          2613,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   64,  1969,   510,   286,   257, 10586,   290,   257, 10211,   220,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "        [   32,  2266,  4512,  5059,   866,   257,  4512,  2610,   351,   257,\n",
      "           582,  2641,    13,   220, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]]), 'clip_embedding': tensor([[-0.0016,  0.0080, -0.0039,  ...,  0.0536,  0.0089,  0.0238],\n",
      "        [-0.0928,  0.0170, -0.0262,  ...,  0.0603, -0.0265,  0.0162],\n",
      "        [-0.0033,  0.0171, -0.0041,  ...,  0.0240, -0.0074, -0.0083],\n",
      "        [ 0.0231,  0.0002, -0.0651,  ...,  0.0113,  0.0049,  0.0327]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'caption_text': ['A group of people riding on the back of an elephant.', 'a man jumping up a little while hitting a tennis ball ', 'a close up of a keyboard and a mouse ', 'A red train driving down a train track with a man inside. '], 'image_id': tensor([512533, 105399, 456666, 517032])}\n"
     ]
    }
   ],
   "source": [
    "# View one batch\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    # Dataloader is smart: will stack non-tensor items as well\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c87b35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Epoch [1/1], Step [1/103529], Loss: 9.6917\n",
      "Batch 1 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 2 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 3 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 4 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 5 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 6 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 7 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 8 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 9 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 10 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 11 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 12 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 13 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 14 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 15 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 16 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 17 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 18 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n",
      "Batch 19 contents:\n",
      " token_ids shape: torch.Size([4, 50])\n",
      " clip_embedding shape: torch.Size([4, 512])\n",
      " attention_mask shape: torch.Size([4, 50])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m mapping_network \u001b[38;5;241m=\u001b[39m MLPMappingNetwork(\n\u001b[0;32m      2\u001b[0m     prefix_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m ClipCapModel(\n\u001b[0;32m      6\u001b[0m     mapping_network\u001b[38;5;241m=\u001b[39mmapping_network\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hoxia\\Documents\\NLDeeznuts\\gpt2-image-captioning\\src\\train.py:65\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, model, batch_size, num_epochs, device, outputs_dir)\u001b[0m\n\u001b[0;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     64\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 65\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     68\u001b[0m     loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    233\u001b[0m         group,\n\u001b[0;32m    234\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m         state_steps,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[1;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adamw.py:426\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    425\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m device_beta1)\n\u001b[1;32m--> 426\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    429\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mapping_network = MLPMappingNetwork(\n",
    "    prefix_length=10\n",
    ")\n",
    "\n",
    "model = ClipCapModel(\n",
    "    mapping_network=mapping_network\n",
    ")\n",
    "\n",
    "train(dataset=dataset, model=model, batch_size=batch_size, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c4e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
